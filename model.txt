import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error

# =============== DATA PREP ===============
df = ...  # your DataFrame

num_cols = [...]  # 222 numeric cols
cat_cols = [...]  # 8 categorical cols

for c in cat_cols:
    df[c], _ = pd.factorize(df[c], sort=True)

X = df[num_cols + cat_cols].fillna(0)
y = df['target_total_premium_pmpm']

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42
)

cat_indices = [X.columns.get_loc(c) for c in cat_cols]

# =============== RANDOM SEARCH ===============
lgb_estimator = LGBMRegressor(objective='regression', random_state=42, n_jobs=-1)

param_dist = {
    'num_leaves': [31, 63, 127],
    'max_depth': [-1, 5, 10],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [500, 1000, 2000],
    'min_child_samples': [20, 50, 100],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0]
}

random_search = RandomizedSearchCV(
    estimator=lgb_estimator,
    param_distributions=param_dist,
    n_iter=20,
    scoring='neg_root_mean_squared_error',
    cv=3,
    verbose=2,
    random_state=42
)

random_search.fit(
    X_train, y_train,
    categorical_feature=cat_indices,
)

print("Best CV RMSE:", -random_search.best_score_)
print("Best hyperparams:", random_search.best_params_)

# =============== FINAL MODEL ===============
best_params = random_search.best_params_
final_model = LGBMRegressor(
    objective='regression', 
    random_state=42, 
    n_jobs=-1,
    **best_params
)

final_model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_val, y_val)],
    eval_metric='rmse',
    early_stopping_rounds=50,
    categorical_feature=cat_indices,
    verbose=50
)

y_pred_val = final_model.predict(X_val)
rmse_val = mean_squared_error(y_val, y_pred_val, squared=False)
print(f"Final Validation RMSE: {rmse_val:.4f}")

evals_result = final_model.evals_result_
plt.plot(evals_result['training']['rmse'], label='Train RMSE')
plt.plot(evals_result['valid_1']['rmse'], label='Val RMSE')
plt.xlabel("Iterations")
plt.ylabel("RMSE")
plt.legend()
plt.title("Training vs. Validation RMSE (LightGBM)")
plt.show()

importances = final_model.feature_importances_
importance_df = pd.DataFrame({
    'feature': X.columns,
    'importance': importances
}).sort_values('importance', ascending=False)

print("Top 10 Features:")
print(importance_df.head(10))


import pandas as pd

importances = final_model.feature_importances_
features = X.columns

importance_df = pd.DataFrame({
    'feature': features,
    'importance': importances
}).sort_values('importance', ascending=False)

print("Top 20 Features:")
print(importance_df.head(20))

# Plot
import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.barh(importance_df['feature'].head(20)[::-1], importance_df['importance'].head(20)[::-1])
plt.title("Top 20 Feature Importances (LGBM w/ Tuned Hyperparams)")
plt.xlabel("Importance")
plt.show()
