import pandas as pd
import numpy as np
from scipy import stats
from statsmodels.tsa.stattools import adfuller, grangercausalitytests
from google.cloud.bigquery import Client
import warnings

warnings.filterwarnings('ignore')

class FeatureSelectionPipeline:
    def __init__(self, project_id, dataset_id, table_id, date_col, unique_id_col):
        self.client = Client(project=project_id)
        self.dataset_id = dataset_id
        self.table_id = table_id
        self.date_col = date_col
        self.unique_id_col = unique_id_col
        self.df = None
        self.selected_df = None
        self.transformed_df = None
        self.feature_groups = {}
    
    def fetch_data(self, query_filter=None):
        query = f"SELECT * FROM {self.dataset_id}.{self.table_id}"
        if query_filter:
            query += f" WHERE {query_filter}"
        self.df = self.client.query(query).to_dataframe()
        print("Data fetched successfully.")
    
    def filter_data(self, unique_id_value, cutoff_date):
        self.selected_df = self.df.loc[
            (self.df[self.unique_id_col] == unique_id_value) & 
            (self.df[self.date_col] < cutoff_date)
        ].copy().reset_index(drop=True)
        print(f"Filtered data shape: {self.selected_df.shape}")

    def check_negative_values(self, columns):
        negative_columns = [col for col in columns if (self.selected_df[col] <= 0).any()]
        return negative_columns

    def boxcox_transform(self, columns):
        self.transformed_df = self.selected_df.copy()
        for col in columns:
            if (self.transformed_df[col] > 0).all():
                self.transformed_df[col], _ = stats.boxcox(self.transformed_df[col])
            else:
                print(f"Skipped Box-Cox transformation for column {col} due to non-positive values.")
        print("Box-Cox transformation complete.")
    
    def find_constant_columns(self, columns):
        return [col for col in columns if self.transformed_df[col].nunique() == 1]

    def adf_test(self, series, significance=0.05):
        result = adfuller(series)
        return result[1] > significance  # Returns True if non-stationary

    def make_stationary(self, columns):
        non_stationary_cols = [col for col in columns if self.adf_test(self.transformed_df[col])]
        diff_df = self.transformed_df.copy()
        for col in non_stationary_cols:
            diff_df[col] = diff_df[col].diff().dropna()
            if self.adf_test(diff_df[col]):
                diff_df.drop(columns=[col], inplace=True)  # Drop if still non-stationary
        self.transformed_df = diff_df.dropna().copy()
        print("Data stationarized.")

    def granger_causality_test(self, maxlag=12, pval_threshold=0.05):
        causality_results = {}
        for col_x in self.transformed_df.columns:
            for col_y in self.transformed_df.columns:
                if col_x != col_y:
                    test_result = grangercausalitytests(
                        self.transformed_df[[col_x, col_y]].dropna(), 
                        maxlag=maxlag, verbose=False
                    )
                    min_pval = min([test_result[i + 1][0]['ssr_chi2test'][1] for i in range(maxlag)])
                    if min_pval < pval_threshold:
                        if col_x not in causality_results:
                            causality_results[col_x] = []
                        causality_results[col_x].append(col_y)
        return causality_results
    
    def cross_correlation_filter(self, columns, threshold=0.9):
        corr_matrix = self.transformed_df[columns].corr().abs()
        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]
        return [col for col in columns if col not in to_drop]
    
    def select_features(self, category_dict, corr_threshold=0.6):
        final_features = {}
        for category, cols in category_dict.items():
            cols = [col for col in cols if col in self.transformed_df.columns]
            causality_filtered = self.cross_correlation_filter(cols, threshold=corr_threshold)
            final_features[category] = causality_filtered
        self.feature_groups = final_features
        print("Feature selection completed.")
    
    def run_pipeline(self, unique_id_value, cutoff_date, sel_columns, category_dict, corr_threshold=0.6):
        self.filter_data(unique_id_value, cutoff_date)
        
        negative_columns = self.check_negative_values(sel_columns)
        sel_columns = [col for col in sel_columns if col not in negative_columns]
        
        self.boxcox_transform(sel_columns)
        
        constant_columns = self.find_constant_columns(sel_columns)
        sel_columns = [col for col in sel_columns if col not in constant_columns]
        
        self.make_stationary(sel_columns)
        
        causality_results = self.granger_causality_test()
        print("Causality test completed.")

        self.select_features(category_dict, corr_threshold)
        
        print("Pipeline executed successfully.")
        return self.feature_groups

# Usage Example
pipeline = FeatureSelectionPipeline(
    project_id='your_project_id', 
    dataset_id='anbc-hcb-dev', 
    table_id='pricing_arme_ds_hcb_dev.TMP_TM_ALL_FEATURES_TARGET_modeling_20241015', 
    date_col='date', 
    unique_id_col='unique_id'
)

# Define required columns and categories
selected_columns = ['date', 'unemployment_rate', 'inflation_value', 'us_interest_rate',
                    'consumer_sentiment', 'total_consumer_debt', 'total_consumer_debt_monthlyrate',
                    'total_group_cnt', 'total_member_cnt', 'bkt_1_M_member_perc',
                    'bkt_1_F_member_perc', 'bkt_2_M_member_perc', 'bkt_2_F_member_perc',
                    'bkt_3_M_member_perc', 'bkt_3_F_member_perc', 'bkt_4_M_member_perc',
                    'bkt_4_F_member_perc', 'gnrc_cnt', 'jcode_cnt', 'brnd_cnt', 'new_drug_cnt',
                    'jcode_allowed', 'jcode_paid', 'jcode_3k_allowed', 'jcode_3k_paid',
                    'jcode_top15_allowed', 'jcode_top15_paid', 'chronic_allowed', 'chronic_paid',
                    'acute_facility_cnt', 'bh_facility_cnt', 'facility_cnt', 'non_facility_cnt',
                    'nursing_cnt', 'healthcare_construction_spending', 'medical_care_cpi',
                    'std_arme_risk_score', 'std_arme_pmpm_pred', 'mean_arme_risk_score', 'mean_arme_pmpm_pred', 
                    'pme_cnt', 'agesexfactor', 'ip_pmpm', 'op_pmpm', 'phy_pmpm', 'mh_pmpm',
                    'ip', 'phy', 'op', 'rx', 'med_pmpm', 'rx_pmpm', 'total_pmpm']

category_dict = {
    "ip": ["ip", "facility_cnt", "healthcare_construction_spending"],
    "op": ["op", "nursing_cnt", "bh_facility_cnt"],
    # Define other categories similarly...
}

final_features = pipeline.run_pipeline(
    unique_id_value='all', 
    cutoff_date='2022-08-01',
    sel_columns=selected_columns,
    category_dict=category_dict,
    corr_threshold=0.6
)

print(final_features)
